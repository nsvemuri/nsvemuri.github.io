# Hands-on introduction to RL



### Objective

To improve the RL literacy

### What You Will Learn

In this codelab, you will learn about:

*   A very simple Grid world navigation RL problem
*   Introduction to Value based & Policy gradient based RL techniques
*   Solve Grid world problem using TD Learning methods
*   Solve Grid world problem using Monte Carlo Learning methods
*   Solve Grid world problem using Policy Gradient Learning methods
*   Solve Grid world problem using Dynamic programming (TBD)

Note: This is NOT an extensive tutorial covering RL. This is meant to bring down
the barrier & motivate the audience to learn Reinforcement learning


### Prerequisites

*   Python programming
*   Have basic understanding of running python in colab
*   Nice to Have: Read specific chapters of Richard Sutton's book:  http://incompleteideas.net/book/the-book-2nd.html (Chapters 3-7 & 13 are relevant to this tutorial)
    </section>


### Basic Assumptions

*   Reader understands the following concepts: Agent, Environment, State,
    Reward, Action, Episode, Policy:
    *   A policy helps the agent take appropriate actions depending on the state
        it is currently in, with an ulterior motive to maximise the total
        rewards earned
    *   An episode consists of a complete sequences of actions agent took and
        states it navigated through until it reaches a terminal state
    *   Specific rewards are received from the environment when agent takes
        actions from the given states



### Initial Reading

*   Read Chapter 3 for an introduction to basic concepts of RL
*   Read Chapter 4 for an introduction to Dynamic Programming


### Next [Grid World Navigation Problem](gridworld.md)
